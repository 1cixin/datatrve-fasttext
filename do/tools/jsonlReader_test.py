import json
from multiprocessing.dummy import freeze_support
import os
import sys
import io
from datatrove.io import DataFolder
from datatrove.pipeline.readers import JsonlReader
from datatrove.pipeline.writers import JsonlWriter
from datatrove.executor.local import LocalPipelineExecutor
from loguru import logger

def main():
    # ==================== 1. å¼ºåˆ¶å…¨å±€UTF-8ç¯å¢ƒ ====================
    os.environ.update({
        "PYTHONUTF8": "1",
        "PYTHONIOENCODING": "utf-8",
        "DATATROVE_COLORIZE_LOGS": "0",
        "NO_COLOR": "1"
    })

    # é‡å®šå‘æ ‡å‡†è¾“å‡º
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

    # ==================== 2. é…ç½®æ—¥å¿—ç³»ç»Ÿ ====================
    logger.remove()
    logger.add(sys.stderr, format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")
    logger.add("test_jsonlreader.log", encoding="utf-8", rotation="10 MB")

    # ==================== 3. å‡†å¤‡æµ‹è¯•æ•°æ® ====================
    TEST_DATA = [
        {"text": "æ™®é€šASCIIæ–‡æœ¬", "meta": {"id": 1}},
        {"text": "ä¸­æ–‡æµ‹è¯•", "meta": {"id": 2}},
        {"text": "ç‰¹æ®Šç¬¦å· â˜…â˜†â™¡", "meta": {"id": 3}},
        {"text": "Emojiæµ‹è¯• ğŸ“ŠğŸ“ˆ", "meta": {"id": 4}}
    ]

    input_dir = "./input_data"
    output_dir = "./test_output"
    os.makedirs(input_dir, exist_ok=True)
    os.makedirs(output_dir, exist_ok=True)

    # å†™å…¥æµ‹è¯•JSONLæ–‡ä»¶ï¼ˆUTF-8ç¼–ç ï¼‰
    input_file = os.path.join(input_dir, "/part_000047.jsonl")
    with open(input_file, "w", encoding="utf-8") as f:
        for item in TEST_DATA:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    # ==================== 4. é…ç½®å¹¶è¿è¡Œç®¡é“ ====================
    try:
        logger.info("=== å¼€å§‹JsonlReaderæµ‹è¯• ===")
        
        # æ¨èæ–¹å¼ - åœ¨åˆ›å»ºDataFolderæ—¶æŒ‡å®šç¼–ç 
        data_folder = DataFolder("./input_data", encoding="utf-8") 

        # ç„¶ååœ¨Readerä¸­ä½¿ç”¨è¿™ä¸ªDataFolder
        reader = JsonlReader(data_folder=data_folder)

        # # å…³é”®é…ç½®ï¼šæ˜¾å¼æŒ‡å®šç¼–ç 
        # reader = JsonlReader(
        #     input_dir,
        #     encoding="utf-8",  # å¿…é¡»æ˜ç¡®æŒ‡å®š
        #     errors="replace",  # å¤„ç†éæ³•å­—ç¬¦
        #     compression=None   # æ˜ç¡®ç¦ç”¨å‹ç¼©
        # )
        
        writer = JsonlWriter(output_dir)
        
        pipeline = [reader, writer]
        
        # æ‰§è¡Œç®¡é“
        executor = LocalPipelineExecutor(
            pipeline,
            tasks=1,
            logging_dir=output_dir
        )
        
        executor.run()
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        output_file = os.path.join(output_dir, "0.jsonl")
        if os.path.exists(output_file):
            with open(output_file, "r", encoding="utf-8") as f:
                lines = [json.loads(line) for line in f]
                logger.success(f"æˆåŠŸå¤„ç† {len(lines)} æ¡è®°å½•")
                for i, item in enumerate(lines[:2]):  # æ‰“å°å‰ä¸¤æ¡éªŒè¯
                    logger.info(f"è®°å½•{i+1}: {str(item)[:100]}...")
        else:
            logger.error("è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        # æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¸Šä¸‹æ–‡
        import traceback
        logger.error(traceback.format_exc())

    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        import shutil
        shutil.rmtree(input_dir, ignore_errors=True)
        shutil.rmtree(output_dir, ignore_errors=True)
        logger.info("å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶")

    logger.info("=== æµ‹è¯•ç»“æŸ ===")
    
    pass

if __name__ == '__main__':
    freeze_support()  # Windowså¤šè¿›ç¨‹å¿…é¡»è°ƒç”¨
    main()  # å°†åŸæœ‰ä»£ç ç§»åˆ°main()å‡½æ•°ä¸­